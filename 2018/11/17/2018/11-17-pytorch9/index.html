<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> PyTorch 学习笔记（九） · Qiyexuxu</title><meta name="description" content="PyTorch 学习笔记（九） - David Wang"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://blog.keeplearning.group/atom.xml" title="Qiyexuxu"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/logo.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/abnerwang" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">PyTorch 学习笔记（九）</h1><div class="tags"><a href="/tags/PyTorch/" class="tag-title">#PyTorch</a></div><div class="post-info">Nov 17, 2018</div><div class="post-content"><p>本节实现一个训练线性回归参数的例子，线性回归的损失函数为：$loss=\frac{1}{2} \sum_{i=1}^{N}(y_{i}-(wx_{i}+b))^2$，然后利用随机梯度下降法更新参数 $w$ 和 $b$ 来最小化损失函数，最终学得 $w$ 和 $b$ 的值。  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">device = t.device(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子，保证在不同电脑上运行时下面的输出一致</span></span><br><span class="line">t.manual_seed(<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_fake_data</span><span class="params">(batch_size=<span class="number">8</span>)</span>:</span></span><br><span class="line">    x = t.rand(batch_size, <span class="number">1</span>, device=device) * <span class="number">5</span></span><br><span class="line">    y = x * <span class="number">2</span> + <span class="number">3</span> + t.randn(batch_size, <span class="number">1</span>, device=device)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机初始化参数</span></span><br><span class="line">w = t.rand(<span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line">b = t.zeros(<span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.02</span>  <span class="comment"># 设置学习率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x, y = get_fake_data(batch_size=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward: 计算loss</span></span><br><span class="line">    y_pred = x.mm(w) + b.expand_as(y)</span><br><span class="line">    loss = <span class="number">0.5</span> * (y_pred - y) ** <span class="number">2</span></span><br><span class="line">    loss = loss.mean()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward: 手动计算梯度</span></span><br><span class="line">    dloss = <span class="number">1</span></span><br><span class="line">    dy_pred = dloss * (y_pred - y)</span><br><span class="line"></span><br><span class="line">    dw = x.t().mm(dy_pred)</span><br><span class="line">    db = dy_pred.sum()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    w.sub_(lr * dw)</span><br><span class="line">    b.sub_(lr * db)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ii % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 画图</span></span><br><span class="line">        x = t.arange(<span class="number">0</span>, <span class="number">6</span>).view(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">        x = x.float()</span><br><span class="line">        y = x.mm(w.cpu()) + b.cpu().expand_as(x)</span><br><span class="line">        plt.plot(x.cpu().numpy(), y.cpu().numpy())  <span class="comment"># predicted</span></span><br><span class="line"></span><br><span class="line">        x2, y2 = get_fake_data(batch_size=<span class="number">32</span>)</span><br><span class="line">        plt.scatter(x2.cpu().numpy(), y2.cpu().numpy())  <span class="comment"># true data</span></span><br><span class="line"></span><br><span class="line">        plt.xlim(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">        plt.ylim(<span class="number">0</span>, <span class="number">13</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'w: '</span>, w.item(), <span class="string">'b: '</span>, b.item())</span><br></pre></td></tr></table></figure>
<hr>
<p>笔记来源：<a href="https://github.com/chenyuntc/pytorch-book" target="_blank" rel="noopener">《pytorch-book》</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2018/11/17/2018/11-17-pytorch8/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'abnerwang';
var disqus_identifier = '2018/11/17/2018/11-17-pytorch9/';
var disqus_title = 'PyTorch 学习笔记（九）';
var disqus_url = 'http://blog.keeplearning.group/2018/11/17/2018/11-17-pytorch9/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//abnerwang.disqus.com/count.js" async></script><div class="copyright"><p>© 2014 - 2018 <a href="http://blog.keeplearning.group">David Wang</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
tex2jax: { inlineMath: [ ["$", "$"], ["\\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
messageStyle: "none"
});
</script></body></html>