<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> PyTorch 学习笔记（一） · Qiyexuxu</title><meta name="description" content="PyTorch 学习笔记（一） - David Wang"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://blog.keeplearning.group/atom.xml" title="Qiyexuxu"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/logo.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/abnerwang" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">PyTorch 学习笔记（一）</h1><div class="tags"><a href="/tags/PyTorch/" class="tag-title">#PyTorch</a></div><div class="post-info">Nov 14, 2018</div><div class="post-content"><p>1 . <code>Tensor</code> 可以认为是一个高维数组，可以使用 GPU 进行加速。   </p>
<p>Input:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line">x = t.Tensor(<span class="number">5</span>, <span class="number">3</span>)    <span class="comment"># 只分配了空间，未初始化</span></span><br><span class="line">x = t.Tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># 使用 [0, 1] 均匀分布随机初始化二维数组</span></span><br><span class="line">x = t.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># 查看 x 的形状</span></span><br><span class="line">print(x.size())</span><br><span class="line"><span class="comment"># 查看 x 中列的个数，两种写法等价</span></span><br><span class="line">print(x.size()[<span class="number">1</span>])</span><br><span class="line">print(x.size(<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><img src="http://wx4.sinaimg.cn/mw690/79225320gy1fx7j8w2u2qj20z9092wf3.jpg" alt="运行结果"><br><code>torch.Size</code> 是 tuple 对象的子类，因此它支持 tuple 的所有操作，如 <code>x.size()[0]</code> 等。<br><a id="more"></a></p>
<p>2 . 加法的三种写法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = t.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x + y)   <span class="comment"># 加法的第一种写法</span></span><br><span class="line">print(t.add(x, y))   <span class="comment"># 加法的第二种写法</span></span><br><span class="line"><span class="comment"># 加法的第三种写法：指定加法结果的输出目标为 result</span></span><br><span class="line">result = t.Tensor(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">t.add(x, y, out=result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'最初 y'</span>)</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># 普通加法，不改变 y 的内容</span></span><br><span class="line">y.add(x)</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># inplace 加法，改变 y 的内容</span></span><br><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>
<p>函数名后面带下划线 <code>_</code> 的函数会改变 Tensor 本身。</p>
<p>3 . Tensor 与 Numpy。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:, <span class="number">1</span>]   <span class="comment"># 选取 x 的第一列所有内容，与 Numpy 相似</span></span><br></pre></td></tr></table></figure>
<p>Tensor 和 Numpy 的数组之间的互操作非常容易且快速，对于 Tensor 不支持的操作，可以先转换为 Numpy 数组处理，之后再转换回 Tensor。  </p>
<p>Input:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensor <span class="keyword">as</span> t</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = t.ones(<span class="number">5</span>)   <span class="comment"># 新建一个全 1 的 Tensor</span></span><br><span class="line">print(a)</span><br><span class="line">b = a.numpy()   <span class="comment"># Tensor ----&gt; Numpy</span></span><br><span class="line">print(b)</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line">b = t.from_numpy(a)   <span class="comment"># Numpy ----&gt; Tensor</span></span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># Tensor 与 Numpy 共享内存</span></span><br><span class="line">b.add_(<span class="number">1</span>)    <span class="comment"># 以 _ 结尾的函数会修改 Tensor 自身</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><img src="http://wx4.sinaimg.cn/mw690/79225320gy1fx7kkcurzdj214m05mjrm.jpg" alt=""><br>Tensor 和 Numpy 对象共享内存，如果其中一个变了，另外一个也会随之改变。</p>
<p>4 . 如果想获取某一个元素的值，可以使用 <code>scalar.item</code>，直接 <code>tensor[idx]</code> 得到的还是一个 tensor，一个 0-dim 的 tensor，一般称为 scalar。  </p>
<p>Input:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scalar = b[<span class="number">0</span>]</span><br><span class="line">print(scalar)</span><br><span class="line">print(scalar.size())  <span class="comment"># 0-dim</span></span><br><span class="line">print(scalar.item())</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><img src="http://wx2.sinaimg.cn/mw690/79225320ly1fx7m1ulcjhj213s02uaa3.jpg" alt="">  </p>
<p>Input:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 注意和 scalar 的区别</span></span><br><span class="line">tensor = t.tensor([<span class="number">2</span>])</span><br><span class="line">print(tensor)</span><br><span class="line">print(tensor.size())</span><br><span class="line"><span class="comment"># 只有一个元素的 tensor 也可以调用 tensor.item()</span></span><br><span class="line">print(tensor.item())</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><img src="http://wx4.sinaimg.cn/mw690/79225320ly1fx7misoww4j213x02yq2v.jpg" alt=""></p>
<p>5 . <code>t.tensor()</code> 总会进行数据拷贝，新 tensor 和原来的数据不共享内存，如果想要共享内存的话，建议使用 <code>torch.from_numpy()</code> 或者 <code>tensor.detach()</code> 来新建一个 tensor，二者共享内存。  </p>
<p>Input:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor = t.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">old_tensor = tensor</span><br><span class="line">new_tensor = t.tensor(old_tensor)</span><br><span class="line">new_tensor[<span class="number">0</span>] = <span class="number">1111</span></span><br><span class="line">print(old_tensor)</span><br><span class="line">print(new_tensor)</span><br><span class="line">new_tensor = old_tensor.detach()</span><br><span class="line">new_tensor[<span class="number">0</span>] = <span class="number">1111</span></span><br><span class="line">print(old_tensor)</span><br><span class="line">print(new_tensor)</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><img src="http://wx3.sinaimg.cn/mw690/79225320gy1fx7mtib98oj214103ojrh.jpg" alt=""></p>
<p>6 . Tensor 可以通过 <code>.cuda</code> 方法转换为 GPU 的 Tensor，从而享受 GPU 带来的加速运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在不支持 CUDA 的机器上，下一步还是在 CPU 上运行</span></span><br><span class="line">device = t.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> t.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">x = x.to(device)</span><br><span class="line">y = y.to(device)</span><br><span class="line">z = x + y</span><br><span class="line">print(z)</span><br></pre></td></tr></table></figure>
<hr>
<p>笔记来源：<a href="https://github.com/chenyuntc/pytorch-book" target="_blank" rel="noopener">《pytorch-book》</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2018/11/14/2018/11-14-pytorch2/" class="prev">上一篇</a><a href="/2017/07/31/2017/07-31-learn-program/" class="next">下一篇</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'abnerwang';
var disqus_identifier = '2018/11/14/2018/11-14-pytorch1/';
var disqus_title = 'PyTorch 学习笔记（一）';
var disqus_url = 'http://blog.keeplearning.group/2018/11/14/2018/11-14-pytorch1/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//abnerwang.disqus.com/count.js" async></script><div class="copyright"><p>© 2014 - 2019 <a href="http://blog.keeplearning.group">David Wang</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
tex2jax: { inlineMath: [ ["$", "$"], ["\\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
messageStyle: "none"
});
</script></body></html>